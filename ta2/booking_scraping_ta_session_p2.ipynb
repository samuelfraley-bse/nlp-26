{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TA Session: Web Scraping for Difference-in-Differences Analysis\n",
    "## Scraping Hotel Prices from Booking.com\n",
    "\n",
    "**Course:** Introduction to Text Mining and Natural Language Processing  \n",
    "**Session:** TA: Project Design and Getting the Text     \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "#### *Disclaimers*\n",
    "\n",
    "- Easiest way for this to run properly: [install Astral's UV](https://docs.astral.sh/uv/getting-started/installation/).\n",
    "- Then just run `uv sync` to install all dependecies.\n",
    "- Make sure you have Google Chrome installed as well, using the default installation method.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Section 2: Robust example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üõ†Ô∏è Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Selenium imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException, \n",
    "    NoSuchElementException,\n",
    "    StaleElementReferenceException\n",
    ")\n",
    "\n",
    "# For automatic chromedriver management\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# For parsing HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üåê Understanding Booking.com URL Structure\n",
    "\n",
    "Before we scrape, let's understand how Booking.com URLs work.\n",
    "\n",
    "A typical search URL looks like:\n",
    "```\n",
    "https://www.booking.com/searchresults.html?ss=Barcelona&checkin=2026-06-04&checkout=2026-06-11&group_adults=2&no_rooms=1&selected_currency=EUR\n",
    "```\n",
    "\n",
    "Key parameters:\n",
    "- `ss` = Search string (city name)\n",
    "- `checkin` = Check-in date (YYYY-MM-DD)\n",
    "- `checkout` = Check-out date (YYYY-MM-DD)\n",
    "- `group_adults` = Number of adults\n",
    "- `no_rooms` = Number of rooms\n",
    "- `selected_currency` = Currency code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_booking_url(city, checkin_date, nights=7, adults=2, rooms=1, currency=\"EUR\"):\n",
    "    \"\"\"\n",
    "    Build a Booking.com search URL.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    city : str\n",
    "        City name to search\n",
    "    checkin_date : str\n",
    "        Check-in date in YYYY-MM-DD format\n",
    "    nights : int\n",
    "        Number of nights (default: 7)\n",
    "    adults : int\n",
    "        Number of adults (default: 2)\n",
    "    rooms : int\n",
    "        Number of rooms (default: 1)\n",
    "    currency : str\n",
    "        Currency code (default: EUR)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Complete Booking.com search URL\n",
    "    \"\"\"\n",
    "    # Calculate checkout date\n",
    "    checkin = datetime.strptime(checkin_date, \"%Y-%m-%d\")\n",
    "    checkout = checkin + timedelta(days=nights)\n",
    "    checkout_date = checkout.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Build URL\n",
    "    base_url = \"https://www.booking.com/searchresults.html\"\n",
    "    params = {\n",
    "        \"ss\": city,\n",
    "        \"checkin\": checkin_date,\n",
    "        \"checkout\": checkout_date,\n",
    "        \"group_adults\": adults,\n",
    "        \"no_rooms\": rooms,\n",
    "        \"selected_currency\": currency\n",
    "    }\n",
    "    \n",
    "    # Construct query string\n",
    "    query_string = \"&\".join([f\"{k}={v}\" for k, v in params.items()])\n",
    "    full_url = f\"{base_url}?{query_string}\"\n",
    "    \n",
    "    return full_url\n",
    "\n",
    "# Test the function\n",
    "test_url = build_booking_url(\"Barcelona\", \"2026-06-04\")\n",
    "print(\"Example URL:\")\n",
    "print(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üöó Setting Up Selenium WebDriver\n",
    "\n",
    "We use Selenium because Booking.com loads content dynamically with JavaScript. A simple HTTP request won't get us all the hotel listings.\n",
    "\n",
    "### Important Configuration Notes:\n",
    "- We run Chrome in **headless mode** (no visible browser window) for speed\n",
    "- We add options to avoid detection as a bot\n",
    "- We use random delays to be respectful to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driver(headless=True):\n",
    "    \"\"\"\n",
    "    Create and configure a Selenium Chrome WebDriver.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    headless : bool\n",
    "        If True, run browser without GUI (faster, recommended for scraping)\n",
    "        If False, show browser window (useful for debugging)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    webdriver.Chrome : Configured Chrome driver\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless=new\")  # New headless mode\n",
    "    \n",
    "    # Essential options to avoid detection and ensure stability\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1400,900\")\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "    \n",
    "    # Pretend to be a real browser\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    # Set a realistic user agent\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "    \n",
    "    # Accept cookies by default (helps with some sites)\n",
    "    chrome_options.add_argument(\"--lang=en-US\")\n",
    "    \n",
    "    # Create driver with automatic chromedriver management\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # Set page load timeout\n",
    "    driver.set_page_load_timeout(30)\n",
    "    \n",
    "    # Execute script to mask webdriver detection\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    return driver\n",
    "\n",
    "print(\"‚úÖ Driver creation function defined!\")\n",
    "print(\"‚ö†Ô∏è  We'll create the actual driver when we start scraping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Scraping Functions\n",
    "\n",
    "Now we define the core scraping logic. This is the **most important part** of the notebook.\n",
    "\n",
    "### Strategy:\n",
    "1. Load the search results page\n",
    "2. Handle the cookie consent popup (if it appears)\n",
    "3. Scroll down to load all hotels (Booking.com uses infinite scroll)\n",
    "4. Extract hotel information from each listing\n",
    "5. Return structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_delay(min_sec=1, max_sec=3):\n",
    "    \"\"\"\n",
    "    Wait for a random amount of time to avoid detection.\n",
    "    Being a good citizen: don't hammer the server!\n",
    "    \"\"\"\n",
    "    delay = random.uniform(min_sec, max_sec)\n",
    "    time.sleep(delay)\n",
    "    return delay\n",
    "\n",
    "\n",
    "def handle_cookie_popup(driver):\n",
    "    \"\"\"\n",
    "    Try to dismiss the cookie consent popup if it appears.\n",
    "    Booking.com shows this on first visit.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Wait a bit for popup to appear\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Try different possible button selectors\n",
    "        cookie_button_selectors = [\n",
    "            \"button#onetrust-accept-btn-handler\",\n",
    "            \"button[id*='accept']\",\n",
    "            \"button[class*='cookie-accept']\",\n",
    "            \"//button[contains(text(), 'Accept')]\",\n",
    "            \"//button[contains(text(), 'Aceptar')]\"\n",
    "        ]\n",
    "        \n",
    "        for selector in cookie_button_selectors:\n",
    "            try:\n",
    "                if selector.startswith(\"//\"):\n",
    "                    # XPath selector\n",
    "                    button = driver.find_element(By.XPATH, selector)\n",
    "                else:\n",
    "                    # CSS selector\n",
    "                    button = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                \n",
    "                button.click()\n",
    "                print(\"    ‚úÖ Cookie popup dismissed\")\n",
    "                time.sleep(1)\n",
    "                return True\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "        \n",
    "        print(\"    ‚ÑπÔ∏è  No cookie popup found (or already dismissed)\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è  Cookie handling error (non-critical): {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def scroll_to_load_hotels(driver, max_scrolls=10, scroll_pause=2):\n",
    "    \"\"\"\n",
    "    Scroll down the page to load more hotels.\n",
    "    Booking.com uses lazy loading / infinite scroll.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    driver : webdriver\n",
    "        Selenium WebDriver instance\n",
    "    max_scrolls : int\n",
    "        Maximum number of scroll actions\n",
    "    scroll_pause : float\n",
    "        Seconds to wait after each scroll for content to load\n",
    "    \"\"\"\n",
    "    print(f\"    üìú Scrolling to load hotels (max {max_scrolls} scrolls)...\")\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    for i in range(max_scrolls):\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # Wait for new content to load\n",
    "        time.sleep(scroll_pause)\n",
    "        \n",
    "        # Check if we've reached the bottom\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            print(f\"    ‚úÖ Reached bottom after {i+1} scrolls\")\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    # Scroll back to top\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hotel_data(driver):\n",
    "    \"\"\"\n",
    "    Extract hotel information from the current search results page.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of dict : Each dict contains hotel name, price, and description\n",
    "    \n",
    "    Note: Booking.com's HTML structure changes frequently!\n",
    "    If this function stops working, you may need to inspect the page\n",
    "    and update the selectors.\n",
    "    \"\"\"\n",
    "    hotels = []\n",
    "    \n",
    "    # Get page source and parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    # Find all hotel property cards\n",
    "    # These selectors may need updating if Booking.com changes their HTML\n",
    "    property_cards = soup.find_all('div', {'data-testid': 'property-card'})\n",
    "    \n",
    "    if not property_cards:\n",
    "        # Try alternative selector\n",
    "        property_cards = soup.find_all('div', {'class': re.compile(r'property-card')})\n",
    "    \n",
    "    if not property_cards:\n",
    "        # Another fallback - look for hotel listing containers\n",
    "        property_cards = soup.find_all('div', {'class': re.compile(r'sr_property_block')})\n",
    "    \n",
    "    print(f\"    üìä Found {len(property_cards)} hotel cards\")\n",
    "    \n",
    "    for card in property_cards:\n",
    "        try:\n",
    "            hotel_data = {\n",
    "                'hotel': None,\n",
    "                'price': None,\n",
    "                'text': None\n",
    "            }\n",
    "            \n",
    "            # ----- Extract Hotel Name -----\n",
    "            # Try multiple selectors for hotel name\n",
    "            name_element = card.find('div', {'data-testid': 'title'})\n",
    "            if not name_element:\n",
    "                name_element = card.find('h3')\n",
    "            if not name_element:\n",
    "                name_element = card.find('span', {'class': re.compile(r'hotel-name')})\n",
    "            if not name_element:\n",
    "                name_element = card.find('a', {'class': re.compile(r'hotel_name_link')})\n",
    "            \n",
    "            if name_element:\n",
    "                hotel_data['hotel'] = name_element.get_text(strip=True)\n",
    "            \n",
    "            # ----- Extract Price -----\n",
    "            # Price is usually in a span with specific data-testid or class\n",
    "            price_element = card.find('span', {'data-testid': 'price-and-discounted-price'})\n",
    "            if not price_element:\n",
    "                price_element = card.find('span', {'class': re.compile(r'price')})\n",
    "            if not price_element:\n",
    "                # Sometimes price is in a div\n",
    "                price_element = card.find('div', {'data-testid': re.compile(r'price')})\n",
    "            \n",
    "            if price_element:\n",
    "                price_text = price_element.get_text(strip=True)\n",
    "                # Extract numeric value from price string (e.g., \"‚Ç¨ 1,234\" -> 1234)\n",
    "                price_numbers = re.findall(r'[\\d,\\.]+', price_text.replace(',', ''))\n",
    "                if price_numbers:\n",
    "                    # Take the first (or largest) number found\n",
    "                    try:\n",
    "                        hotel_data['price'] = float(price_numbers[0].replace('.', '').replace(',', '.'))\n",
    "                    except ValueError:\n",
    "                        hotel_data['price'] = None\n",
    "            \n",
    "            # ----- Extract Description/Text -----\n",
    "            # This is typically a short preview or the hotel type\n",
    "            # We collect multiple text elements and combine them\n",
    "            text_parts = []\n",
    "            \n",
    "            # Hotel type (e.g., \"Hotel\", \"Apartment\", \"Hostel\")\n",
    "            type_elem = card.find('span', {'data-testid': 'accommodation-type'})\n",
    "            if type_elem:\n",
    "                text_parts.append(type_elem.get_text(strip=True))\n",
    "            \n",
    "            # Location info\n",
    "            location_elem = card.find('span', {'data-testid': 'address'})\n",
    "            if location_elem:\n",
    "                text_parts.append(location_elem.get_text(strip=True))\n",
    "            \n",
    "            # Distance from center\n",
    "            distance_elem = card.find('span', {'data-testid': 'distance'})\n",
    "            if distance_elem:\n",
    "                text_parts.append(distance_elem.get_text(strip=True))\n",
    "            \n",
    "            # Review summary or highlights\n",
    "            review_elem = card.find('div', {'class': re.compile(r'review')})\n",
    "            if review_elem:\n",
    "                text_parts.append(review_elem.get_text(strip=True))\n",
    "            \n",
    "            # Any other descriptive text in the card\n",
    "            for p_tag in card.find_all('p'):\n",
    "                p_text = p_tag.get_text(strip=True)\n",
    "                if len(p_text) > 20:  # Only meaningful text\n",
    "                    text_parts.append(p_text)\n",
    "            \n",
    "            # Combine all text parts\n",
    "            hotel_data['text'] = ' | '.join(text_parts) if text_parts else None\n",
    "            \n",
    "            # ----- Validate and Add -----\n",
    "            # Only add if we got at least a name\n",
    "            if hotel_data['hotel']:\n",
    "                hotels.append(hotel_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è  Error parsing one hotel card: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return hotels\n",
    "\n",
    "\n",
    "print(\"‚úÖ Hotel extraction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_booking_search(driver, city, checkin_date, max_scrolls=5):\n",
    "    \"\"\"\n",
    "    Main function to scrape hotel data for a single city and date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    driver : webdriver\n",
    "        Selenium WebDriver instance (already created)\n",
    "    city : str\n",
    "        City name to search\n",
    "    checkin_date : str\n",
    "        Check-in date in YYYY-MM-DD format\n",
    "    max_scrolls : int\n",
    "        Maximum scroll attempts to load more hotels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of dict : Hotel data with keys 'hotel', 'price', 'text'\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Scraping: {city} | Check-in: {checkin_date}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Build URL\n",
    "    url = build_booking_url(city, checkin_date)\n",
    "    print(f\"    üåê URL: {url[:80]}...\")\n",
    "    \n",
    "    # Load page\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(\"    ‚úÖ Page loaded\")\n",
    "    except TimeoutException:\n",
    "        print(\"    ‚ùå Page load timeout!\")\n",
    "        return []\n",
    "    \n",
    "    # Handle cookie popup\n",
    "    handle_cookie_popup(driver)\n",
    "    \n",
    "    # Random delay to be polite\n",
    "    random_delay(2, 4)\n",
    "    \n",
    "    # Scroll to load more hotels\n",
    "    scroll_to_load_hotels(driver, max_scrolls=max_scrolls)\n",
    "    \n",
    "    # Extract hotel data\n",
    "    hotels = extract_hotel_data(driver)\n",
    "    \n",
    "    print(f\"    ‚úÖ Extracted {len(hotels)} hotels\")\n",
    "    \n",
    "    # Add city and date to each record\n",
    "    for hotel in hotels:\n",
    "        hotel['city'] = city\n",
    "        hotel['date'] = checkin_date\n",
    "    \n",
    "    return hotels\n",
    "\n",
    "\n",
    "print(\"‚úÖ Main scraping function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üöÄ DEMO - Scraping One Hotel Search\n",
    "\n",
    "Let's run a live demonstration. We'll scrape hotels in **Barcelona** for **one check-in date**.\n",
    "\n",
    "### ‚ö†Ô∏è Important Notes:\n",
    "1. **Run this cell carefully** - it will open a browser (even in headless mode, it uses resources)\n",
    "2. **Be patient** - scraping takes time (30-60 seconds per search)\n",
    "3. **Don't run too many times** - Booking.com may block you if you make too many requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# DEMO: Scrape ONE search (Barcelona, one date)\n",
    "# ===========================================\n",
    "\n",
    "# Demo parameters\n",
    "demo_city = \"Barcelona\"\n",
    "demo_checkin = \"2026-06-02\"  # Primavera Sound week\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üé¨ LIVE DEMO: Scraping Booking.com\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"City: {demo_city}\")\n",
    "print(f\"Check-in: {demo_checkin}\")\n",
    "print(f\"Nights: 7\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create driver\n",
    "# Set headless=False if you want to SEE the browser (useful for debugging)\n",
    "print(\"\\nüöó Creating WebDriver...\")\n",
    "driver = create_driver(headless=True)  # Change to False to see the browser\n",
    "print(\"‚úÖ Driver created!\")\n",
    "\n",
    "try:\n",
    "    # Run the scraping\n",
    "    demo_hotels = scrape_booking_search(driver, demo_city, demo_checkin, max_scrolls=3)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä DEMO RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if demo_hotels:\n",
    "        # Convert to DataFrame for nice display\n",
    "        demo_df = pd.DataFrame(demo_hotels)\n",
    "        print(f\"\\nTotal hotels scraped: {len(demo_df)}\")\n",
    "        print(\"\\nFirst 5 hotels:\")\n",
    "        print(demo_df[['hotel', 'price', 'city', 'date']].head())\n",
    "        \n",
    "        print(\"\\nSample hotel with description:\")\n",
    "        print(\"-\" * 40)\n",
    "        sample = demo_hotels[0]\n",
    "        print(f\"Hotel: {sample['hotel']}\")\n",
    "        print(f\"Price: ‚Ç¨{sample['price']}\")\n",
    "        print(f\"Text: {sample['text'][:200] if sample['text'] else 'N/A'}...\")\n",
    "    else:\n",
    "        print(\"‚ùå No hotels extracted. The HTML structure may have changed.\")\n",
    "        print(\"   You may need to inspect the page and update selectors.\")\n",
    "\n",
    "finally:\n",
    "    # Always close the driver!\n",
    "    driver.quit()\n",
    "    print(\"\\nüöó Driver closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "\n",
    "> #### Try to use other code that's at least slightly different to this for your final product ;)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booking-scraping (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
