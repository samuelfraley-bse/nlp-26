{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea1e5fa-6572-4905-8144-84685ef450ec",
   "metadata": {},
   "source": [
    "![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40c9b8-54d0-4925-aacc-9db2addb3bbf",
   "metadata": {},
   "source": [
    "# Introduction to Text Mining and Natural Language Processing\n",
    "\n",
    "Hannes Mueller\n",
    "\n",
    "\n",
    "## Session 3: Pre-processing\n",
    "\n",
    "This material is just to support the lecture Session 3. It generates the examples the students see of a text in various stages of pre-processing. The code here is useful to understand as we will use these three options as standard pre-processing options throughout the course.\n",
    "\n",
    "The code also shows how the text can be collected in the document term matrix. This is not strictly speaking part of pre-processing but is very useful to understand the goal of pre-processing in the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a025b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e03f13-8cb8-44ac-91b4-e8f4dd2ca5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw Original Text ===\n",
      "\n",
      "Palestinian President  Mahmoud Abbas said Wednesday that late former Israeli President  Shimon Peres had exerted unremitting efforts to make peace until  the last moment of his life. \"He (Peres) exerted unremitting efforts to reach a permanent  peace since Oslo agreement was signed with Israel in 1993 until  the last moment in his life,\" Abbas said in a condolence letter to  Peres' family, carried by state news agency WAFA. In his letter, Abbas expressed deep grief and sorrow for Peres'  passing. \"He was a partner in making the peace of the brave with  late Palestinian leader Yasser Arafat and late Israeli Prime  Minister Yitzhak Rabin.\" Earlier on Wednesday, Israel announced that Peres died in a  hospital in the suburbs of Tel Aviv at the age of 93. \"We are so happy about the news of former Israeli president's  death. It is not only us, but all the Palestinian people are happy  about the news of Peres' death,\" he said. \"This man committed  crimes and shed the blood of our people.\" Abu Zuhri, whose movement is classified as a terrorist group  and rejects to recognize Israel and the peace process, said:  \"Peres was the last founder of this entity (Israel) and we believe  it is a start of a new stage of the Israeli occupation's  weakness.\"\n",
      "\n",
      "\n",
      "=== Cleaned Text (Lowercased, No Punctuation, Stopwords Removed) ===\n",
      "\n",
      "palestinian president mahmoud abbas said wednesday late former israeli president shimon peres exerted unremitting efforts make peace last moment life peres exerted unremitting efforts reach permanent peace since oslo agreement signed israel 1993 last moment life abbas said condolence letter peres family carried state news agency wafa letter abbas expressed deep grief sorrow peres passing partner making peace brave late palestinian leader yasser arafat late israeli prime minister yitzhak rabin earlier wednesday israel announced peres died hospital suburbs tel aviv age 93 happy news former israeli presidents death us palestinian people happy news peres death said man committed crimes shed blood people abu zuhri whose movement classified terrorist group rejects recognize israel peace process said peres last founder entity israel believe start new stage israeli occupations weakness\n",
      "\n",
      "\n",
      "=== Stemmed Text (Stopwords Removed) ===\n",
      "\n",
      "palestinian presid mahmoud abba said wednesday late former isra presid shimon pere exert unremit effort make peac last moment life pere exert unremit effort reach perman peac sinc oslo agreement sign israel 1993 last moment life abba said condol letter pere famili carri state news agenc wafa letter abba express deep grief sorrow pere pass partner make peac brave late palestinian leader yasser arafat late isra prime minist yitzhak rabin earlier wednesday israel announc pere die hospit suburb tel aviv age 93 happi news former isra presid death us palestinian peopl happi news pere death said man commit crime shed blood peopl abu zuhri whose movement classifi terrorist group reject recogn israel peac process said pere last founder entiti israel believ start new stage isra occup weak\n",
      "\n",
      "\n",
      "=== Lemmatized Text (Stopwords Removed, Original Casing) ===\n",
      "\n",
      "palestinian President Mahmoud Abbas say Wednesday late israeli President Shimon Peres exert unremitting effort peace moment life Peres exert unremitting effort reach permanent peace Oslo agreement sign Israel 1993 moment life Abbas say condolence letter Peres family carry state news agency WAFA letter Abbas express deep grief sorrow Peres pass partner make peace brave late palestinian leader Yasser Arafat late israeli Prime Minister Yitzhak Rabin early Wednesday Israel announce Peres die hospital suburb Tel Aviv age 93 happy news israeli president death palestinian people happy news Peres death say man commit crime shed blood people Abu Zuhri movement classify terrorist group reject recognize Israel peace process say Peres founder entity Israel believe start new stage israeli occupation weakness\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "# Download NLTK data (if needed)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#for later\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Original Text\n",
    "# =============================================================================\n",
    "\n",
    "text = (\n",
    "    \"Palestinian President  Mahmoud Abbas said Wednesday that late former Israeli President  \"\n",
    "    \"Shimon Peres had exerted unremitting efforts to make peace until  the last moment of his life. \"\n",
    "    \"\\\"He (Peres) exerted unremitting efforts to reach a permanent  peace since Oslo agreement was signed \"\n",
    "    \"with Israel in 1993 until  the last moment in his life,\\\" Abbas said in a condolence letter to  Peres' family, \"\n",
    "    \"carried by state news agency WAFA. In his letter, Abbas expressed deep grief and sorrow for Peres'  passing. \"\n",
    "    \"\\\"He was a partner in making the peace of the brave with  late Palestinian leader Yasser Arafat and late \"\n",
    "    \"Israeli Prime  Minister Yitzhak Rabin.\\\" Earlier on Wednesday, Israel announced that Peres died in a  hospital \"\n",
    "    \"in the suburbs of Tel Aviv at the age of 93. \\\"We are so happy about the news of former Israeli president's  death. \"\n",
    "    \"It is not only us, but all the Palestinian people are happy  about the news of Peres' death,\\\" he said. \"\n",
    "    \"\\\"This man committed  crimes and shed the blood of our people.\\\" Abu Zuhri, whose movement is classified as a \"\n",
    "    \"terrorist group  and rejects to recognize Israel and the peace process, said:  \\\"Peres was the last founder of this \"\n",
    "    \"entity (Israel) and we believe  it is a start of a new stage of the Israeli occupation's  weakness.\\\"\"\n",
    ")\n",
    "\n",
    "print(\"=== Raw Original Text ===\\n\")\n",
    "print(text)\n",
    "print(\"\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# Option 1: Lowercasing, Punctuation Removal, and Stopword Removal\n",
    "# =============================================================================\n",
    "\n",
    "# Lowercase the text.\n",
    "text_lower = text.lower()\n",
    "\n",
    "# Remove punctuation using regex (keeping only word characters and whitespace).\n",
    "text_no_punct = re.sub(r'[^\\w\\s]', '', text_lower)\n",
    "\n",
    "# Get the set of English stopwords.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize the cleaned text.\n",
    "tokens = word_tokenize(text_no_punct)\n",
    "\n",
    "# Filter out stopwords.\n",
    "filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# Join tokens back into a single string.\n",
    "cleaned_text = \" \".join(filtered_tokens)\n",
    "\n",
    "print(\"=== Cleaned Text (Lowercased, No Punctuation, Stopwords Removed) ===\\n\")\n",
    "print(cleaned_text)\n",
    "print(\"\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# Option 2: Stemming (Using Cleaned Text)\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize the Porter Stemmer.\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Apply stemming to each filtered token.\n",
    "stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "\n",
    "# Join the stemmed tokens into a single string.\n",
    "stemmed_text = \" \".join(stemmed_tokens)\n",
    "\n",
    "print(\"=== Stemmed Text (Stopwords Removed) ===\\n\")\n",
    "print(stemmed_text)\n",
    "print(\"\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# Option 3: Lemmatization (Only Stopwords Removed; No Lowercasing)\n",
    "# =============================================================================\n",
    "# Load the spaCy English language model.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the original text with spaCy.\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract the lemma for each token, filtering out punctuation and stopwords.\n",
    "# Note: spaCy flags stop words (token.is_stop) based on its internal list.\n",
    "lemmatized_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.lemma_.strip() != '']\n",
    "\n",
    "# Join the lemmatized tokens into a single string.\n",
    "lemmatized_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "print(\"=== Lemmatized Text (Stopwords Removed, Original Casing) ===\\n\")\n",
    "print(lemmatized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3b287-25ea-4792-a2e9-fd1f9321dcb2",
   "metadata": {},
   "source": [
    "# Building the Document Term Matrix\n",
    "\n",
    "You could add all three documents but one would never want to mix different pre-processing so I am just passing one document. Experiment by exchanging the cleaned_text below for: \n",
    "\n",
    "    - stemmed_text   # As above, but with stemming.\n",
    "    - lemmatized_text # Original casing, stopwords removed and lemmatized.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c17edb9-4c41-4389-89e4-08bed74d459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (Unigrams & Bigrams):\n",
      "{'palestinian': 0, 'presid': 1, 'mahmoud': 2, 'abba': 3, 'said': 4, 'wednesday': 5, 'late': 6, 'former': 7, 'isra': 8, 'shimon': 9, 'pere': 10, 'exert': 11, 'unremit': 12, 'effort': 13, 'make': 14, 'peac': 15, 'last': 16, 'moment': 17, 'life': 18, 'reach': 19, 'perman': 20, 'sinc': 21, 'oslo': 22, 'agreement': 23, 'sign': 24, 'israel': 25, '1993': 26, 'condol': 27, 'letter': 28, 'famili': 29, 'carri': 30, 'state': 31, 'news': 32, 'agenc': 33, 'wafa': 34, 'express': 35, 'deep': 36, 'grief': 37, 'sorrow': 38, 'pass': 39, 'partner': 40, 'brave': 41, 'leader': 42, 'yasser': 43, 'arafat': 44, 'prime': 45, 'minist': 46, 'yitzhak': 47, 'rabin': 48, 'earlier': 49, 'announc': 50, 'die': 51, 'hospit': 52, 'suburb': 53, 'tel': 54, 'aviv': 55, 'age': 56, '93': 57, 'happi': 58, 'death': 59, 'us': 60, 'peopl': 61, 'man': 62, 'commit': 63, 'crime': 64, 'shed': 65, 'blood': 66, 'abu': 67, 'zuhri': 68, 'whose': 69, 'movement': 70, 'classifi': 71, 'terrorist': 72, 'group': 73, 'reject': 74, 'recogn': 75, 'process': 76, 'founder': 77, 'entiti': 78, 'believ': 79, 'start': 80, 'new': 81, 'stage': 82, 'occup': 83, 'weak': 84, 'palestinian presid': 85, 'presid mahmoud': 86, 'mahmoud abba': 87, 'abba said': 88, 'said wednesday': 89, 'wednesday late': 90, 'late former': 91, 'former isra': 92, 'isra presid': 93, 'presid shimon': 94, 'shimon pere': 95, 'pere exert': 96, 'exert unremit': 97, 'unremit effort': 98, 'effort make': 99, 'make peac': 100, 'peac last': 101, 'last moment': 102, 'moment life': 103, 'life pere': 104, 'effort reach': 105, 'reach perman': 106, 'perman peac': 107, 'peac sinc': 108, 'sinc oslo': 109, 'oslo agreement': 110, 'agreement sign': 111, 'sign israel': 112, 'israel 1993': 113, '1993 last': 114, 'life abba': 115, 'said condol': 116, 'condol letter': 117, 'letter pere': 118, 'pere famili': 119, 'famili carri': 120, 'carri state': 121, 'state news': 122, 'news agenc': 123, 'agenc wafa': 124, 'wafa letter': 125, 'letter abba': 126, 'abba express': 127, 'express deep': 128, 'deep grief': 129, 'grief sorrow': 130, 'sorrow pere': 131, 'pere pass': 132, 'pass partner': 133, 'partner make': 134, 'peac brave': 135, 'brave late': 136, 'late palestinian': 137, 'palestinian leader': 138, 'leader yasser': 139, 'yasser arafat': 140, 'arafat late': 141, 'late isra': 142, 'isra prime': 143, 'prime minist': 144, 'minist yitzhak': 145, 'yitzhak rabin': 146, 'rabin earlier': 147, 'earlier wednesday': 148, 'wednesday israel': 149, 'israel announc': 150, 'announc pere': 151, 'pere die': 152, 'die hospit': 153, 'hospit suburb': 154, 'suburb tel': 155, 'tel aviv': 156, 'aviv age': 157, 'age 93': 158, '93 happi': 159, 'happi news': 160, 'news former': 161, 'presid death': 162, 'death us': 163, 'us palestinian': 164, 'palestinian peopl': 165, 'peopl happi': 166, 'news pere': 167, 'pere death': 168, 'death said': 169, 'said man': 170, 'man commit': 171, 'commit crime': 172, 'crime shed': 173, 'shed blood': 174, 'blood peopl': 175, 'peopl abu': 176, 'abu zuhri': 177, 'zuhri whose': 178, 'whose movement': 179, 'movement classifi': 180, 'classifi terrorist': 181, 'terrorist group': 182, 'group reject': 183, 'reject recogn': 184, 'recogn israel': 185, 'israel peac': 186, 'peac process': 187, 'process said': 188, 'said pere': 189, 'pere last': 190, 'last founder': 191, 'founder entiti': 192, 'entiti israel': 193, 'israel believ': 194, 'believ start': 195, 'start new': 196, 'new stage': 197, 'stage isra': 198, 'isra occup': 199, 'occup weak': 200}\n",
      "\n",
      "Total vocabulary size: 201\n",
      "\n",
      "\n",
      "Document-Term Matrix (rows: documents, columns: token counts):\n",
      "[[3 3 1 3 4 2 3 2 4 1 7 2 2 2 2 4 3 2 2 1 1 1 1 1 1 4 1 1 2 1 1 1 3 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 2 2 2 1 2 1 2 2 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "\n",
      "Document-Term Matrix DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palestinian</th>\n",
       "      <th>presid</th>\n",
       "      <th>mahmoud</th>\n",
       "      <th>abba</th>\n",
       "      <th>said</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>late</th>\n",
       "      <th>former</th>\n",
       "      <th>isra</th>\n",
       "      <th>shimon</th>\n",
       "      <th>...</th>\n",
       "      <th>last founder</th>\n",
       "      <th>founder entiti</th>\n",
       "      <th>entiti israel</th>\n",
       "      <th>israel believ</th>\n",
       "      <th>believ start</th>\n",
       "      <th>start new</th>\n",
       "      <th>new stage</th>\n",
       "      <th>stage isra</th>\n",
       "      <th>isra occup</th>\n",
       "      <th>occup weak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cleaned</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         palestinian  presid  mahmoud  abba  said  wednesday  late  former  \\\n",
       "Cleaned            3       3        1     3     4          2     3       2   \n",
       "\n",
       "         isra  shimon  ...  last founder  founder entiti  entiti israel  \\\n",
       "Cleaned     4       1  ...             1               1              1   \n",
       "\n",
       "         israel believ  believ start  start new  new stage  stage isra  \\\n",
       "Cleaned              1             1          1          1           1   \n",
       "\n",
       "         isra occup  occup weak  \n",
       "Cleaned           1           1  \n",
       "\n",
       "[1 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# Document Term Matrix Construction Example\n",
    "#############################################\n",
    "\n",
    "# For demonstration purposes, we create a list of one document only.\n",
    "# In practice, you might have many documents (e.g., from a corpus).\n",
    "documents = [\n",
    "    stemmed_text]   # Lowercased, punctuation removed, stopwords removed.\n",
    "\n",
    "\n",
    "# Define a helper function to generate n-grams.\n",
    "def generate_ngrams(tokens, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams from a list of tokens.\n",
    "    For example, n=2 returns bigrams.\n",
    "    \n",
    "    Args:\n",
    "        tokens (List[str]): List of tokens.\n",
    "        n (int): The number for the n-gram.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: A list of n-gram strings.\n",
    "    \"\"\"\n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "# Process each document to extract unigrams and bigrams.\n",
    "documents_ngrams = []  # Will hold the combined list of unigrams and bigrams for each document.\n",
    "for doc in documents:\n",
    "    # Each document is already a string of tokens separated by a space.\n",
    "    tokens = doc.split()  \n",
    "    unigrams = tokens\n",
    "    bigrams = generate_ngrams(tokens, 2)\n",
    "    combined = unigrams + bigrams\n",
    "    documents_ngrams.append(combined)\n",
    "\n",
    "# Build the vocabulary. Each unique token (from unigrams and bigrams) is assigned a unique index.\n",
    "vocab = {}\n",
    "index = 0\n",
    "for doc in documents_ngrams:\n",
    "    for token in doc:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "\n",
    "print(\"Vocabulary (Unigrams & Bigrams):\")\n",
    "print(vocab)\n",
    "print(\"\\nTotal vocabulary size:\", len(vocab))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Now, create the document-term matrix.\n",
    "# Rows represent documents and columns represent token counts according to our vocabulary.\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the document-term matrix with zeros.\n",
    "dtm = np.zeros((len(documents_ngrams), len(vocab)), dtype=int)\n",
    "\n",
    "# Fill in the document-term matrix.\n",
    "for doc_id, doc in enumerate(documents_ngrams):\n",
    "    for token in doc:\n",
    "        token_index = vocab[token]\n",
    "        dtm[doc_id, token_index] += 1\n",
    "\n",
    "print(\"Document-Term Matrix (rows: documents, columns: token counts):\")\n",
    "print(dtm)\n",
    "\n",
    "# For better visualization, let's print the matrix as a DataFrame with token (column) labels.\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the dtm.\n",
    "dtm_df = pd.DataFrame(dtm, columns=[token for token, idx in sorted(vocab.items(), key=lambda x: x[1])])\n",
    "dtm_df.index = ['Cleaned']\n",
    "\n",
    "print(\"\\nDocument-Term Matrix DataFrame:\")\n",
    "dtm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1605ef3-0b2f-45a4-a855-25ff923a6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document term matrix has size: (1, 121)\n",
      "The column names of the matrix are:\n",
      "['1993' '93' 'Abbas' 'Abu' 'Arafat' 'Aviv' 'Earlier' 'He' 'In' 'Israel'\n",
      " 'Israeli' 'It' 'Mahmoud' 'Minister' 'Oslo' 'Palestinian' 'Peres'\n",
      " 'President' 'Prime' 'Rabin' 'Shimon' 'Tel' 'This' 'WAFA' 'We' 'Wednesday'\n",
      " 'Yasser' 'Yitzhak' 'Zuhri' 'about' 'age' 'agency' 'agreement' 'all' 'and'\n",
      " 'announced' 'are' 'as' 'at' 'believe' 'blood' 'brave' 'but' 'by'\n",
      " 'carried' 'classified' 'committed' 'condolence' 'crimes' 'death' 'deep'\n",
      " 'died' 'efforts' 'entity' 'exerted' 'expressed' 'family' 'for' 'former'\n",
      " 'founder' 'grief' 'group' 'had' 'happy' 'he' 'his' 'hospital' 'in' 'is'\n",
      " 'it' 'last' 'late' 'leader' 'letter' 'life' 'make' 'making' 'man'\n",
      " 'moment' 'movement' 'new' 'news' 'not' 'occupation' 'of' 'on' 'only'\n",
      " 'our' 'partner' 'passing' 'peace' 'people' 'permanent' 'president'\n",
      " 'process' 'reach' 'recognize' 'rejects' 'said' 'shed' 'signed' 'since'\n",
      " 'so' 'sorrow' 'stage' 'start' 'state' 'suburbs' 'terrorist' 'that' 'the'\n",
      " 'this' 'to' 'unremitting' 'until' 'us' 'was' 'we' 'weakness' 'whose'\n",
      " 'with']\n"
     ]
    }
   ],
   "source": [
    "#just for fun lets do the same with the countvectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range = (1,1), lowercase=False)\n",
    "cv.fit([text])\n",
    "\n",
    "\n",
    "\n",
    "vectorized_text=cv.transform([text])\n",
    "vectorized_text=vectorized_text.todense()\n",
    "print(\"document term matrix has size:\", vectorized_text.shape)\n",
    "\n",
    "print(\"The column names of the matrix are:\")\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de91a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document term matrix has size: (1, 81)\n",
      "The column names of the matrix are:\n",
      "['1993' '93' 'Abbas' 'Abu' 'Arafat' 'Aviv' 'Israel' 'Mahmoud' 'Minister'\n",
      " 'Oslo' 'Peres' 'President' 'Prime' 'Rabin' 'Shimon' 'Tel' 'WAFA'\n",
      " 'Wednesday' 'Yasser' 'Yitzhak' 'Zuhri' 'age' 'agency' 'agreement'\n",
      " 'announce' 'believe' 'blood' 'brave' 'carry' 'classify' 'commit'\n",
      " 'condolence' 'crime' 'death' 'deep' 'die' 'early' 'effort' 'entity'\n",
      " 'exert' 'express' 'family' 'founder' 'grief' 'group' 'happy' 'hospital'\n",
      " 'israeli' 'late' 'leader' 'letter' 'life' 'make' 'man' 'moment'\n",
      " 'movement' 'new' 'news' 'occupation' 'palestinian' 'partner' 'pass'\n",
      " 'peace' 'people' 'permanent' 'president' 'process' 'reach' 'recognize'\n",
      " 'reject' 'say' 'shed' 'sign' 'sorrow' 'stage' 'start' 'state' 'suburb'\n",
      " 'terrorist' 'unremitting' 'weakness']\n"
     ]
    }
   ],
   "source": [
    "#Let's try the same trick with the lemmatized text:\n",
    "cv.fit([lemmatized_text])\n",
    "\n",
    "\n",
    "vectorized_text=cv.transform([text])\n",
    "vectorized_text=vectorized_text.todense()\n",
    "print(\"document term matrix has size:\", vectorized_text.shape)\n",
    "\n",
    "print(\"The column names of the matrix are:\")\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cdc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508f7082",
   "metadata": {},
   "source": [
    "# Homework: process more than one text\n",
    "Write a loop that goes through different texts and implements the document term matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523f976",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-mining-dsdm (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
