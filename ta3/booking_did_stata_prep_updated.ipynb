{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Booking scraping: Stata-ready export + DiD with city/date fixed effects\n",
        "\n",
        "\n",
        "\n",
        "## Why this is needed\n",
        "Stata fails with `r(5101)` because the `text` column contains embedded newlines and problematic quoting. We avoid that by excluding `text` from the Stata import.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8021fb34",
      "metadata": {},
      "source": [
        "![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7489fd",
      "metadata": {},
      "source": [
        "# Introduction to Text Mining and Natural Language Processing\n",
        "\n",
        "Professor: Hannes Mueller\n",
        "TA: Margherita Philipp\n",
        "\n",
        "DiD with scraped data\n",
        "\n",
        "This notebook:\n",
        "1. Loads the original CSV (even if it contains multiline `text`).\n",
        "2. Runs the simple DiD in Python with city and date fixed effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6395f465",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Set paths and load data\n",
        "\n",
        "Update `CSV_PATH` to your local file path. Outputs go to `OUT_DIR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CSV_PATH = Path(r\"data/booking_scraping_combined.csv\")\n",
        "OUT_DIR = Path(r\"output\")\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"CSV_PATH:\", CSV_PATH)\n",
        "print(\"OUT_DIR:\", OUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We rely on pandas‚Äô CSV parser, which can handle multiline quoted strings more robustly than Stata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(CSV_PATH, encoding=\"utf-8\")\n",
        "print(df.shape)\n",
        "df.head()\n",
        "\n",
        "# (20755, 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c2d87f4",
      "metadata": {},
      "source": [
        "## 1) Text features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2753b009",
      "metadata": {},
      "source": [
        "Generated for all groups - can subset later"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8852dd51",
      "metadata": {},
      "source": [
        "### Dictionary terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd179ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "luxury_terms = [\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fac0db0",
      "metadata": {},
      "source": [
        "### Clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b8b50e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.group.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbdf922",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"text_clean\"] = (\n",
        "    df[\"text\"]\n",
        "    .str.lower()\n",
        "    .str.replace(r\"[^\\w\\s\\.-]\", \" \", regex=True)  #[^\\w\\s\\.-] vs [^\\w\\s\\]\n",
        "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "    .str.strip()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac876ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['text', 'text_clean']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b173dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[df.text.isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2426fa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.dropna(subset=[\"text\", \"price\", \"treatCity\", \"treatPeriod\", \"city\", \"date\"]).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88af0502",
      "metadata": {},
      "source": [
        "### Applying the dictionary - with speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a75264a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re   \n",
        "\n",
        "# compile once\n",
        "luxury_pattern1 = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, luxury_terms)) + r\")\\b\")\n",
        "luxury_pattern2 = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, luxury_terms)) + r\")\\b\", re.IGNORECASE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2830bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# choose version of text and pattern\n",
        "\n",
        "text_col = \"text_clean\" # \"text_clean text\n",
        "luxury_pattern = luxury_pattern1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fa7c46",
      "metadata": {},
      "outputs": [],
      "source": [
        "luxury_pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c6961b",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "\n",
        "## OPTION A: python lopp \n",
        "\n",
        "luxury_count = []\n",
        "\n",
        "for txt in df[text_col]:\n",
        "    # if not isinstance(text, str):\n",
        "    #     text = \"\" if text is None else str(text)  # or just \"\"\n",
        "    luxury_count.append(len(luxury_pattern.findall(txt)))\n",
        "\n",
        "df[\"luxury_count_loop\"] = luxury_count\n",
        "\n",
        "# for group 1\n",
        "# text clean + pattern 1: 108 ms ¬± 2.94 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n",
        "# text raw   + pattern 2: 285 ms ¬± 3.8 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
        "\n",
        "# for all groups\n",
        "# text clean + pattern 1: 315 ms ¬± 9.89 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
        "# text raw   + pattern 2: 825 ms ¬± 4.47 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e822adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "\n",
        "## OPTION B: loop inside a function + .apply()\n",
        "\n",
        "def count_luxury(txt: str) -> int:\n",
        "    return len(luxury_pattern.findall(txt))\n",
        "\n",
        "df[\"luxury_count_apply\"] = df[text_col].apply(count_luxury)\n",
        "\n",
        "# group 1:\n",
        "# text clean + pattern 1: 106 ms ¬± 1.58 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n",
        "# text raw   + pattern 2: 285 ms ¬± 8.4 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
        "\n",
        "# for all groups\n",
        "# text clean + pattern 1: 316 ms ¬± 10.9 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
        "# text raw   + pattern 2: 858 ms ¬± 16.9 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06db0e39",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "\n",
        "## OPTION C: Vectorized regex approach\n",
        "\n",
        "df[\"luxury_count_vec\"] = df[text_col].str.count(luxury_pattern)\n",
        "\n",
        "# group 1: \n",
        "# text clean + pattern 1: 104 ms ¬± 1.74 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n",
        "# text raw   + pattern 2: 280 ms ¬± 1.57 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
        "\n",
        "# for all groups\n",
        "# text clean + pattern 1: 308 ms ¬± 2.03 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
        "# text raw   + pattern 2: 884 ms ¬± 22.6 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e28b2c98",
      "metadata": {},
      "source": [
        "### Inspecting matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f1cf0d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "df[\"luxury_matches\"] = df[\"text_clean\"].str.findall(luxury_pattern)\n",
        "df[\"luxury_count\"] = df[\"luxury_matches\"].str.len()\n",
        "\n",
        "# all groups\n",
        "# clean & 1: 317 ms ¬± 9.43 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52efd730",
      "metadata": {},
      "outputs": [],
      "source": [
        "# compare counts\n",
        "df[['text','text_clean','luxury_count_loop', 'luxury_count_apply', 'luxury_count_vec']]\n",
        "\n",
        "# check that none differ\n",
        "df.loc[(df['luxury_count_apply'] != df['luxury_count_apply'])]\n",
        "\n",
        "# inspect matches\n",
        "df[['text','text_clean','luxury_matches', 'luxury_count']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74368b2",
      "metadata": {},
      "source": [
        "### Normalise by description length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb299cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# description length\n",
        "df[\"n_words\"] = df[\"text_clean\"].str.split().str.len()\n",
        "\n",
        "# normalise\n",
        "df[\"luxury_density\"] = df[\"luxury_count\"] / df[\"n_words\"]\n",
        "\n",
        "# quick inspection\n",
        "df[[\"luxury_count\", \"luxury_density\"]].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e478b1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# quick visuals of distributions\n",
        "\n",
        "bin_number = 40\n",
        "\n",
        "df['luxury_count'].plot(kind='hist',\n",
        "                        bins=bin_number, title='Distribution of luxury counts')\n",
        "plt.show()\n",
        "\n",
        "df['luxury_density'].plot(kind='hist',\n",
        "                          bins=bin_number, title='Distribution of luxury nomalised')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb075273",
      "metadata": {},
      "outputs": [],
      "source": [
        "# binarisation suggestions\n",
        "cut_off = 0.013\n",
        "print(\"cut-off = \", cut_off)\n",
        "# print(\"<= cut-off \" , len(df.loc[df['luxury_density']<=cut_off]))\n",
        "# print(\"> cut-off \", len(df.loc[df['luxury_density']>cut_off]))\n",
        "\n",
        "df['luxury_bin'] = (df['luxury_density'] > cut_off).astype(int)\n",
        "df['luxury_bin'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "187a3b0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['luxury_bin', 'luxury_count', 'luxury_density']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc46047",
      "metadata": {},
      "source": [
        "## 2) Check Parallel trends"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791220a9",
      "metadata": {},
      "source": [
        "For a more robust analysis: do an event study\n",
        "- event-time variable\n",
        "- could be nonparametric binned event-study plot or regression-based event study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f442c931",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.sample (5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b596b1e5",
      "metadata": {},
      "source": [
        "### Select a subset of data and inspect hotel numbers and shares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b541c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "group = 4 # 1 (impact), 3 (no impact), 4 & 5 (less good data?)\n",
        "\n",
        "# check what share of observations are in the treated city and which periods are in the treated period \n",
        "df_chosen = df.loc[df['group']==group]\n",
        "df_chosen.date.unique()\n",
        "df_gb = df_chosen.groupby('date').agg({'treatCity':'mean',\n",
        "                               'treatPeriod':'mean'}).reset_index()\n",
        "df_gb.sort_values(\"date\", inplace=True)\n",
        "\n",
        "# (un)treated dates \n",
        "dates_0 = df_gb.loc[df_gb['treatPeriod'] == 0, 'date']\n",
        "dates_1 = df_gb.loc[df_gb['treatPeriod'] == 1, 'date']\n",
        "\n",
        "# save for later - NB works less well for group 1 as no post-treatment control\n",
        "first_date_0 = dates_0.iloc[0]\n",
        "last_date_0  = dates_0.iloc[-1]\n",
        "date_treat_1 = dates_1.iloc[0]\n",
        "\n",
        "df_gb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b486feed",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Share of luxurious hotels in treatment: \", len(df_chosen.loc[(df_chosen['treatPeriod']==1) & (df_chosen['luxury_bin']==1)])/ len(df_chosen.loc[df_chosen['treatPeriod']==1]))\n",
        "print(\"Share of luxurious hotels in control: \", len(df_chosen.loc[(df_chosen['treatPeriod']==0) & (df_chosen['luxury_bin']==1)])/ len(df_chosen.loc[df_chosen['treatPeriod']==0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f7d310",
      "metadata": {},
      "outputs": [],
      "source": [
        "shares = (\n",
        "    df_chosen\n",
        "    .groupby('treatPeriod')['luxury_bin']\n",
        "    .mean()\n",
        ")\n",
        "\n",
        "n_obs = (\n",
        "    df_chosen\n",
        "    .groupby(['treatPeriod', 'date'])['luxury_bin']\n",
        "    .count()\n",
        ")\n",
        "\n",
        "print(\"Share of luxurious hotels in treatment:\", round(shares.loc[1], 4))\n",
        "print(\"Share of luxurious hotels in control:\", round(shares.loc[0], 4))\n",
        "print(\"___\")\n",
        "# change date\n",
        "print(\"Number of luxurious hotels in treatment:\", n_obs.loc[(1, date_treat_1)])\n",
        "print(\"Number of luxurious hotels in (pre-)control:\", n_obs.loc[(0, first_date_0)])\n",
        "print(\"___\")\n",
        "print(\"Number of luxurious hotels in treatment:\", n_obs.loc[(1, date_treat_1)])\n",
        "print(\"Number of luxurious hotels in (after-)control:\", n_obs.loc[(0, last_date_0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10394418",
      "metadata": {},
      "outputs": [],
      "source": [
        "set_lux_treat = set(df_chosen.loc[(df_chosen['treatPeriod']==1) & (df_chosen['luxury_bin']==1)][\"hotel\"])\n",
        "set_lux_contr = set(df_chosen.loc[(df_chosen['treatPeriod']==0) & (df_chosen['luxury_bin']==1)][\"hotel\"])\n",
        "\n",
        "# what does each of these show?\n",
        "set_lux_treat - set_lux_contr\n",
        "set_lux_contr - set_lux_treat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ac1b6b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure date is datetime\n",
        "df_chosen['date'] = pd.to_datetime(df_chosen['date'])\n",
        "\n",
        "# Average price by date and treatment status\n",
        "df_avg = (\n",
        "    df_chosen\n",
        "    .groupby(['date', 'treatCity'], as_index=False)['price']\n",
        "    .mean())\n",
        "\n",
        "df_treated = df_avg[df_avg['treatCity'] == 1]\n",
        "df_control = df_avg[df_avg['treatCity'] == 0]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Treated: points + thin line\n",
        "plt.plot(\n",
        "    df_treated['date'],\n",
        "    df_treated['price'],\n",
        "    marker='o',\n",
        "    linestyle='-',\n",
        "    linewidth=1,\n",
        "    markersize=5,\n",
        "    label=f'Treated: {df_chosen.event_city.unique()[0]}' #'Treated cities'\n",
        ")\n",
        "\n",
        "# Control: points + thin line\n",
        "plt.plot(\n",
        "    df_control['date'],\n",
        "    df_control['price'],\n",
        "    marker='o',\n",
        "    linestyle='-',\n",
        "    linewidth=1,\n",
        "    markersize=5,\n",
        "    label=f'Control: {df_chosen.control_city.unique()[0]}' # Control cities'\n",
        ")\n",
        "\n",
        "# Treatment dates\n",
        "treatment_dates = df_chosen.loc[df_chosen['treatPeriod']==1].date.unique()\n",
        "for d in treatment_dates:\n",
        "    plt.axvline(d, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average price')\n",
        "plt.title(f'Average hotel prices: treated ({df_chosen.event.unique()[0]}) vs control city')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9bbaa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure date is datetime\n",
        "df_chosen['date'] = pd.to_datetime(df_chosen['date'])\n",
        "\n",
        "# Average price by date, treatment status, and luxury bin\n",
        "df_avg = (\n",
        "    df_chosen\n",
        "    .groupby(['date', 'treatCity', 'luxury_bin'], as_index=False)['price']\n",
        "    .mean()\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot 4 lines\n",
        "for treat, treat_label in [(1, 'Treated'), (0, 'Control')]:\n",
        "    for lux, lux_label in [(1, 'Luxury'), (0, 'Non-luxury')]:\n",
        "        tmp = df_avg[(df_avg['treatCity'] == treat) & (df_avg['luxury_bin'] == lux)]\n",
        "\n",
        "        # Style controls\n",
        "        linestyle = '-' if lux == 1 else '--'\n",
        "        color = 'orange' if treat == 1 else 'blue'\n",
        "\n",
        "        plt.plot(\n",
        "            tmp['date'],\n",
        "            tmp['price'],\n",
        "            marker='o',\n",
        "            linestyle=linestyle,\n",
        "            linewidth=1,\n",
        "            markersize=5,\n",
        "            color=color,\n",
        "            label=f'{treat_label} ‚Äî {lux_label}'\n",
        "        )\n",
        "\n",
        "\n",
        "# Treatment dates\n",
        "treatment_dates = df_chosen.loc[df_chosen['treatPeriod'] == 1, 'date'].dropna().unique()\n",
        "for d in treatment_dates:\n",
        "    plt.axvline(d, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average price')\n",
        "plt.title(f'Average hotel prices (treated vs control) split by binarised luxury density')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Run DiD in Python\n",
        "\n",
        "\"Simple\" specification: `ln(price) ~ œÑ (treatCity*treatPeriod) + city FE + date FE`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ab0621",
      "metadata": {},
      "source": [
        "### Transform target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f08e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.sandwich_covariance import cov_cluster_2groups\n",
        "\n",
        "# NB NaN values already dropped\n",
        "df_ln = df.copy()\n",
        "df_ln[\"price\"] = pd.to_numeric(df_ln[\"price\"], errors=\"coerce\")\n",
        "df_ln = df_ln.dropna(subset=[\"price\"]) #(already done)\n",
        "df_ln[\"lnprice\"]=np.log(df_ln[\"price\"]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420b2534",
      "metadata": {},
      "outputs": [],
      "source": [
        "# decide/ double check which groups' data we are working with\n",
        "df_py = df_ln.loc[df_ln.group.isin([3])] # 1,3,4,5\n",
        "\n",
        "df_py.date.unique()\n",
        "df_py.group.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3eb953e",
      "metadata": {},
      "source": [
        "### Run OLS on residuals after ‚Äúabsorbing‚Äù fixed effects via demeaning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc26609",
      "metadata": {},
      "source": [
        " - Instead of adding thousands of dummies, you ‚Äúwithin-transform‚Äù both _ln(price)_ and _treatment_ using `multiway_demean`.\n",
        " - No intercept needed because residualized variables have mean ~0.\n",
        "- Estimate tau and check different error structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e649b146",
      "metadata": {},
      "outputs": [],
      "source": [
        "# function for demeaning\n",
        "def multiway_demean(v, *groups, max_iter=200, tol=1e-10):\n",
        "    \"\"\"\n",
        "    Iteratively residualize v on multiple categorical fixed effects (groups).\n",
        "    v: (n,) array-like\n",
        "    groups: one or more (n,) arrays of group ids (int/str ok)\n",
        "    \"\"\"\n",
        "    v = np.asarray(v, dtype=float)\n",
        "    out = v.copy()\n",
        "\n",
        "    # Ensure groups are 1D arrays\n",
        "    G = [np.asarray(g) for g in groups]\n",
        "    n = len(out)\n",
        "    for g in G:\n",
        "        if g.shape[0] != n:\n",
        "            raise ValueError(\"All group arrays must have same length as v.\")\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        old = out.copy()\n",
        "\n",
        "        for g in G:\n",
        "            # Map group labels to consecutive ints\n",
        "            _, inv = np.unique(g, return_inverse=True)\n",
        "            sums = np.bincount(inv, weights=out)\n",
        "            cnts = np.bincount(inv)\n",
        "            means = sums / cnts\n",
        "            out = out - means[inv]\n",
        "\n",
        "        if np.max(np.abs(out - old)) < tol:\n",
        "            break\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7450f0bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# define some fixed effects - numeric FE codes\n",
        "g_city = df_py[\"city\"].astype(\"category\").cat.codes.to_numpy().astype(int)\n",
        "g_date = df_py[\"date\"].astype(\"category\").cat.codes.to_numpy().astype(int)\n",
        "g_hotel = df_py[\"hotel\"].astype(\"category\").cat.codes.to_numpy().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44f0ad4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# \"Simple\": Treatment = TreatCity √ó TreatPeriod\n",
        "df_py[\"treatment\"] = df_py[\"treatCity\"] * df_py[\"treatPeriod\"]\n",
        "\n",
        "# Within-transform (absorb Fiexed Effects: choose which ones) g_city g_date g_hotel \n",
        "y = multiway_demean(df_py[\"lnprice\"].to_numpy(), g_city, g_date)\n",
        "x = multiway_demean(df_py[\"treatment\"].to_numpy(), g_city, g_date)\n",
        "\n",
        "# OLS on residualized variables (no intercept)\n",
        "res_simple = sm.OLS(y, x).fit()\n",
        "\n",
        "res_simple.params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e57857",
      "metadata": {},
      "source": [
        "NB we now have two coefficients\n",
        "\n",
        "ln(price)=Œ≤1‚Äã‚ãÖtreatment+Œ≤2‚Äã‚ãÖ(treatment√óluxury)+FE+Œµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d77411",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heterogeneous treatment effects by luxury: create interaction dummy\n",
        "lux = df_py[\"luxury_bin\"].to_numpy().astype(int)\n",
        "treat = df_py[\"treatment\"].to_numpy().astype(int)\n",
        "\n",
        "# regressors: treatment and treatment*luxury\n",
        "X = np.column_stack([treat, treat * lux])\n",
        "\n",
        "# absorb date (and more if you want)\n",
        "y = multiway_demean(df_py[\"lnprice\"].to_numpy(), g_city, g_date)\n",
        "\n",
        "X_dm = np.column_stack([\n",
        "    multiway_demean(X[:,0], g_city, g_date),\n",
        "    multiway_demean(X[:,1], g_city, g_date),\n",
        "])\n",
        "\n",
        "res_interact = sm.OLS(y, X_dm).fit()\n",
        "\n",
        "res_interact.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2528f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only controlling for luxury (use treat and lux from above)\n",
        "y_dm = multiway_demean(df_py[\"lnprice\"].to_numpy(), g_city, g_date)\n",
        "\n",
        "treat_dm = multiway_demean(treat, g_city, g_date)\n",
        "lux_dm = multiway_demean(lux, g_city, g_date)\n",
        "X_dm = np.column_stack([treat_dm, lux_dm])\n",
        "\n",
        "res_control = sm.OLS(y_dm, X_dm).fit()\n",
        "\n",
        "res_control.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da2b64c",
      "metadata": {},
      "outputs": [],
      "source": [
        "result_chosen = res_control # res_simple, res_interact, res_control \n",
        " \n",
        "# (a) HC1 robust (Stata: , r)\n",
        "res_hc1 = result_chosen.get_robustcov_results(cov_type=\"HC1\")\n",
        "\n",
        "# (b) Cluster by city (Stata: vce(cluster city))\n",
        "res_cl_city = result_chosen.get_robustcov_results(\n",
        "    cov_type=\"cluster\",\n",
        "    groups=g_city,\n",
        "    use_correction=True  # small-sample correction\n",
        ")\n",
        "\n",
        "# (c) Two-way cluster (city, date) ‚Äì Cameron-Gelbach-Miller\n",
        "# Note: with few clusters, multiway clustering can still be noisy, but this should not return nan here.\n",
        "V_2way, _, _ = cov_cluster_2groups(result_chosen, g_city, g_date)\n",
        "se_2way = float(np.sqrt(V_2way[0, 0]))\n",
        "\n",
        "print(\"obserevations\", len(df_py))\n",
        "\n",
        "print(f\"\\ntau (treatment) = {float(result_chosen.params[0]):.3f}\")\n",
        "\n",
        "print(\"\\nHC1 robust:\")\n",
        "print(f\"  SE = {float(res_hc1.bse[0]):.3f}, p = {float(res_hc1.pvalues[0]):.4g}\")\n",
        "\n",
        "print(\"\\nCluster(city):\")\n",
        "print(f\"  SE = {float(res_cl_city.bse[0]):.3f}, p = {float(res_cl_city.pvalues[0]):.4g}\")\n",
        "\n",
        "print(\"\\nTwo-way cluster(city,date):\")\n",
        "t_2way = float(result_chosen.params[0]) / se_2way\n",
        "print(f\"  SE = {se_2way:.3f}, t = {t_2way:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5164208",
      "metadata": {},
      "source": [
        "### Interpretation (for res_simple on all groups)\n",
        "- estimate is positive (ùúè^=0.227‚Üí about +25% since ùëí 0.227 ‚àí 1 ‚âà 0.255\n",
        "- ‚Äúsignificance‚Äù depends on the error structure: for group = 1\n",
        "    - very significant under HC1\n",
        "    - still significant under city clustering\n",
        "    - borderline under two-way clustering (t ‚âà 1.93)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e786e5",
      "metadata": {},
      "source": [
        "## Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a283f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# old two-way demean\n",
        "# def twoway_demean(v, g1, g2, max_iter=200, tol=1e-10):\n",
        "#     \"\"\"Residualize v w.r.t. additive FE for g1 and g2 via alternating projections.\"\"\"\n",
        "#     v = np.asarray(v, dtype=float)\n",
        "#     out = v.copy()\n",
        "\n",
        "#     for _ in range(max_iter):\n",
        "#         old = out.copy()\n",
        "\n",
        "#         # subtract g1 means\n",
        "#         m1 = np.zeros(g1.max() + 1); c1 = np.zeros(g1.max() + 1)\n",
        "#         np.add.at(m1, g1, out); np.add.at(c1, g1, 1)\n",
        "#         out -= (m1 / c1)[g1]\n",
        "\n",
        "#         # subtract g2 means\n",
        "#         m2 = np.zeros(g2.max() + 1); c2 = np.zeros(g2.max() + 1)\n",
        "#         np.add.at(m2, g2, out); np.add.at(c2, g2, 1)\n",
        "#         out -= (m2 / c2)[g2]\n",
        "\n",
        "#         if np.max(np.abs(out - old)) < tol:\n",
        "#             break\n",
        "\n",
        "#     return out\n",
        "\n",
        "\n",
        "# # Within-transform (absorb Fiexed Effects: choose which ones)\n",
        "# y = twoway_demean(df_py[\"lnprice\"].to_numpy(), g_city, g_date) \n",
        "# x = twoway_demean(df_py[\"treatment\"].to_numpy(), g_city, g_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9dec5eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results Hannes for all groups\n",
        "\n",
        "# tau (treatment) = 0.227\n",
        "\n",
        "# HC1 robust:\n",
        "#   SE = 0.017, p = 4.685e-40\n",
        "\n",
        "# Cluster(city):\n",
        "#   SE = 0.053, p = 0.00358\n",
        "\n",
        "# Two-way cluster(city,date):\n",
        "#   SE = 0.118, t = 1.930"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd423e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "    # \"luxury\", \"luxurious\", \"premium\", \"exclusive\", \"elegant\",\n",
        "    # \"boutique\", \"upscale\", \"high-end\", \"refined\",\n",
        "    # \"spa\", \"wellness\", \"gourmet\", \"fine dining\",\n",
        "    # \"panoramic\", \"rooftop\", \"private\", \"pool\",\n",
        "    # \"designer\", \"bespoke\",\n",
        "    # \"5-star\", \"five-star\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "text-mining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
